{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking file input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def readcorpus():\n",
    "    corpus=[]\n",
    "    fi=open(\"Data/train.txt\",\"r\")\n",
    "    for line in fi:\n",
    "        corpus.append(line[:-1]);\n",
    "    corpus = filter(None, corpus)                                      # Getting rid of NULLS\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making N-Grams DS for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "sentence_end =\".?!\"\n",
    "def ngrams_ds(corpus,n):\n",
    "    final_dict={}\n",
    "    correct=[]\n",
    "    a=0\n",
    "    final_dict['none']={}\n",
    "    for i in range(0,len(corpus)):\n",
    "        right=[]\n",
    "        wrong=[]\n",
    "        error=[]\n",
    "        flag=1\n",
    "        for j in range(0,n):\n",
    "            if(i+j < len(corpus) and corpus[i+j] not in sentence_end):\n",
    "                wrong.append(corpus[i+j].split()[0])\n",
    "                if len(corpus[i+j].split(\"   \")) > 1 :                                # WORD HAS ERROR\n",
    "                    error.append(corpus[i+j].split(\"   \")[2])                         # MAKE ENTRY IN ERROR\n",
    "                    if len(right)>1:\n",
    "                        if(corpus[i+j].split(\"   \")[1] not in right):                 # CHECK FOR REPEAT ERROR TYPE\n",
    "                            right.append(corpus[i+j].split(\"   \")[1])\n",
    "                else:                                                                 # WORD WAS RIGHT\n",
    "                    right.append(corpus[i+j].split()[0])\n",
    "            else:\n",
    "                flag=0\n",
    "                break\n",
    "        \n",
    "        if(flag==1):\n",
    "            for k in error:\n",
    "                if k not in final_dict.keys():                                    # New error type discovered\n",
    "                    final_dict[k]={}\n",
    "                    final_dict[k][tuple(wrong)]={}\n",
    "                    final_dict[k][tuple(wrong)][tuple(right)]=1\n",
    "                else:                                                             # Error type exists Therfore dict exists\n",
    "                    if tuple(wrong) not in final_dict[k].keys():                  # First time wrong n-gram came\n",
    "                        final_dict[k][tuple(wrong)]={}\n",
    "                        final_dict[k][tuple(wrong)][tuple(right)]=1\n",
    "                    else:\n",
    "                        if tuple(right) in final_dict[k][tuple(wrong)].keys():    # for wrong word rigth came again\n",
    "                            final_dict[k][tuple(wrong)][tuple(right)]+=1\n",
    "                        else:                                                     # Although wrong word existed the right came for the first time\n",
    "                            final_dict[k][tuple(wrong)][tuple(right)]=1\n",
    "\n",
    "            correct.append(tuple(right))\n",
    "            \n",
    "    \n",
    "    x=dict(Counter(correct))\n",
    "    final_dict['none']=x\n",
    "    return final_dict\n",
    "\n",
    "\n",
    "## TEST CODE ##\n",
    "\n",
    "final_dict=ngrams_ds(readcorpus(),3)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking test file input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readtestcorpus():\n",
    "    test_corpus=[]\n",
    "    fi=open(\"Data/test.txt\",\"r\")\n",
    "    for line in fi:\n",
    "        test_corpus.append(line[:-1]);\n",
    "    test_corpus = filter(None, test_corpus)                                      # Getting rid of NULLS\n",
    "    return test_corpus[0:len(test_corpus)/10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making N-Grams for test and Calling Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('so', 'vhtr', 'is'), 'none']\n",
      "[('vhtr', 'is', 'environment'), 'none']\n",
      "[('is', 'environment', 'friendly'), 'none']\n",
      "[('environment', 'friendly', 'and'), 'none']\n",
      "[('friendly', 'and', 'the'), 'Srun']\n",
      "[('and', 'the', 'most'), 'none']\n",
      "[('the', 'most', 'optimized'), 'none']\n",
      "[('most', 'optimized', 'solution'), 'none']\n",
      "[('optimized', 'solution', 'towards'), 'none']\n",
      "[('solution', 'towards', 'green'), 'none']\n",
      "[('towards', 'green', 'house'), 'none']\n",
      "[('green', 'house', 'effect'), 'none']\n",
      "[('retrieved', 'on', '5/09/2009.http'), 'none']\n",
      "[('on', '5/09/2009.http', ':'), 'none']\n",
      "[('5/09/2009.http', ':', '//www.purdue.edu/uns/x/2007a/070314agrawalbiomass.html'), 'Nn']\n",
      "[(':', '//www.purdue.edu/uns/x/2007a/070314agrawalbiomass.html', ')'), 'Nn']\n",
      "[('//www.purdue.edu/uns/x/2007a/070314agrawalbiomass.html', ')', 'for'), 'Nn']\n",
      "[(')', 'for', 'instance'), 'none']\n",
      "[('for', 'instance', ','), 'none']\n",
      "[('instance', ',', 'an'), 'none']\n",
      "[(',', 'an', 'insurance'), 'none']\n",
      "[('an', 'insurance', 'company'), 'none']\n",
      "[('insurance', 'company', 'will'), 'none']\n",
      "[('company', 'will', 'refuse'), 'none']\n",
      "[('will', 'refuse', 'to'), 'none']\n",
      "[('refuse', 'to', 'provide'), 'none']\n",
      "[('to', 'provide', 'any'), 'none']\n",
      "[('provide', 'any', 'insurance'), 'none']\n",
      "[('any', 'insurance', 'coverage'), 'none']\n",
      "[('insurance', 'coverage', 'for'), 'none']\n",
      "[('coverage', 'for', 'an'), 'none']\n",
      "[('for', 'an', 'individual'), 'Wci']\n",
      "[('an', 'individual', 'who'), 'none']\n",
      "[('individual', 'who', 'may'), 'none']\n",
      "[('who', 'may', 'have'), 'Vt']\n",
      "[('may', 'have', 'had'), 'none']\n",
      "[('have', 'had', 'been'), 'none']\n",
      "[('had', 'been', 'tested'), 'none']\n",
      "[('been', 'tested', 'positive'), 'none']\n",
      "[('tested', 'positive', 'of'), 'none']\n",
      "[('positive', 'of', 'a'), 'none']\n",
      "[('of', 'a', 'genetic'), 'none']\n",
      "[('a', 'genetic', 'disorder'), 'none']\n",
      "[('genetic', 'disorder', 'or'), 'none']\n",
      "[('disorder', 'or', 'has'), 'none']\n",
      "[('or', 'has', 'a'), 'none']\n",
      "[('has', 'a', 'high'), 'none']\n",
      "[('a', 'high', 'probability'), 'none']\n",
      "[('high', 'probability', 'of'), 'Cit']\n",
      "[('probability', 'of', 'acquiring'), 'Cit']\n",
      "[('of', 'acquiring', 'a'), 'Cit']\n",
      "[('acquiring', 'a', 'genetic'), 'Cit']\n",
      "[('a', 'genetic', 'disorder'), 'none']\n",
      "[('genetic', 'disorder', ','), 'none']\n",
      "[('disorder', ',', 'since'), 'Cit']\n",
      "[(',', 'since', 'the'), 'none']\n",
      "[('since', 'the', 'insurance'), 'none']\n",
      "[('the', 'insurance', 'company'), 'none']\n",
      "[('insurance', 'company', 'finds'), 'none']\n",
      "[('company', 'finds', 'it'), 'none']\n",
      "[('finds', 'it', 'a'), 'none']\n",
      "[('it', 'a', 'loss'), 'none']\n",
      "[('a', 'loss', 'to'), 'none']\n",
      "[('loss', 'to', 'make'), 'none']\n",
      "[('to', 'make', 'a'), 'none']\n",
      "[('make', 'a', 'payout'), 'none']\n",
      "[('a', 'payout', 'to'), 'none']\n",
      "[('payout', 'to', 'an'), 'none']\n",
      "[('to', 'an', \"'already\"), 'none']\n",
      "[('an', \"'already\", 'or'), 'none']\n",
      "[(\"'already\", 'or', 'potentially-sick'), 'none']\n",
      "[('or', 'potentially-sick', \"'\"), 'none']\n",
      "[('potentially-sick', \"'\", 'individual'), 'none']\n",
      "[('in', 'brief', ','), 'none']\n",
      "[('brief', ',', 'with'), 'none']\n",
      "[(',', 'with', 'the'), 'none']\n",
      "[('with', 'the', 'advancement'), 'none']\n",
      "[('the', 'advancement', 'of'), 'none']\n",
      "[('advancement', 'of', 'medical'), 'none']\n",
      "[('of', 'medical', 'technologies'), 'none']\n",
      "[('medical', 'technologies', ','), 'none']\n",
      "[('technologies', ',', 'the'), 'none']\n",
      "[(',', 'the', 'robotic'), 'none']\n",
      "[('the', 'robotic', 'surgery'), 'none']\n",
      "[('robotic', 'surgery', 'systems'), 'none']\n",
      "[('surgery', 'systems', 'are'), 'Rloc-']\n",
      "[('systems', 'are', 'definitely'), 'Rloc-']\n",
      "[('are', 'definitely', 'benefit'), 'Rloc-']\n",
      "[('definitely', 'benefit', 'both'), 'none']\n",
      "[('benefit', 'both', 'the'), 'none']\n",
      "[('both', 'the', 'patients'), 'none']\n",
      "[('the', 'patients', 'and'), 'none']\n",
      "[('patients', 'and', 'the'), 'none']\n",
      "[('and', 'the', 'surgeons'), 'none']\n",
      "[('shantakumar', '1999', ','), 'Mec']\n",
      "[('1999', ',', 'asher'), 'Mec']\n",
      "[(',', 'asher', '1996'), 'Mec']\n",
      "[('asher', '1996', 'and'), 'Mec']\n",
      "[('1996', 'and', '1998'), 'Mec']\n",
      "[('and', '1998', ','), 'Mec']\n",
      "[('1998', ',', 'lee'), 'Mec']\n",
      "[(',', 'lee', '1999'), 'Mec']\n",
      "[('lee', '1999', 'and'), 'Mec']\n",
      "[('1999', 'and', '2001a'), 'Mec']\n",
      "[('and', '2001a', ','), 'Mec']\n",
      "[('2001a', ',', 'have'), 'Mec']\n",
      "[(',', 'have', 'pointed'), 'Rloc-']\n",
      "[('have', 'pointed', 'out'), 'Rloc-']\n",
      "[('pointed', 'out', 'the'), 'none']\n",
      "[('out', 'the', 'lack'), 'Wtone']\n",
      "[('the', 'lack', 'of'), 'none']\n",
      "[('lack', 'of', 'universal'), 'none']\n",
      "[('of', 'universal', 'coverage'), 'none']\n",
      "[('universal', 'coverage', 'and'), 'none']\n",
      "[('coverage', 'and', 'the'), 'none']\n",
      "[('and', 'the', 'lack'), 'none']\n",
      "[('the', 'lack', 'of'), 'none']\n",
      "[('lack', 'of', 'adequacy'), 'Wci']\n",
      "[('of', 'adequacy', 'of'), 'Wci']\n",
      "[('adequacy', 'of', 'funds'), 'Wci']\n",
      "[('of', 'funds', 'for'), 'none']\n",
      "[('funds', 'for', 'retirement'), 'Wci']\n",
      "[('for', 'retirement', 'security'), 'Wci']\n",
      "[('retirement', 'security', 'in'), 'none']\n",
      "[('security', 'in', 'this'), 'ArtOrDet']\n",
      "[('in', 'this', 'cpf'), 'ArtOrDet']\n",
      "[('this', 'cpf', 'scheme'), 'ArtOrDet']\n",
      "[('cpf', 'scheme', ','), 'none']\n",
      "[('scheme', ',', 'especially'), 'none']\n",
      "[(',', 'especially', 'for'), 'none']\n",
      "[('especially', 'for', 'the'), 'none']\n",
      "[('for', 'the', 'low-income'), 'none']\n",
      "[('the', 'low-income', 'elderly'), 'none']\n",
      "[('low-income', 'elderly', '('), 'none']\n",
      "[('elderly', '(', 'as'), 'none']\n",
      "[('(', 'as', 'cited'), 'none']\n",
      "[('as', 'cited', 'in'), 'none']\n",
      "[('cited', 'in', 'david'), 'none']\n",
      "[('in', 'david', 'r.'), 'none']\n",
      "[('david', 'r.', 'phillips'), 'none']\n",
      "[('r.', 'phillips', 'and'), 'none']\n",
      "[('phillips', 'and', 'alfred'), 'none']\n",
      "[('and', 'alfred', 'c.m'), 'none']\n",
      "[('through', 'these', '-'), 'Mec']\n",
      "[('these', '-', 'engineers'), 'Mec']\n",
      "[('-', 'engineers', 'can'), 'Mec']\n",
      "[('engineers', 'can', 'predict'), 'none']\n",
      "[('can', 'predict', 'the'), 'none']\n",
      "[('predict', 'the', 'impact'), 'none']\n",
      "[('the', 'impact', 'of'), 'none']\n",
      "[('impact', 'of', 'a'), 'none']\n",
      "[('of', 'a', 'possible'), 'none']\n",
      "[('a', 'possible', 'defeated'), 'Mec']\n",
      "[('possible', 'defeated', 'in'), 'Mec']\n",
      "[('defeated', 'in', 'current'), 'Mec']\n",
      "[('in', 'current', 'and'), 'none']\n",
      "[('current', 'and', 'faraway'), 'none']\n",
      "[('and', 'faraway', 'situation'), 'Nn']\n",
      "[('faraway', 'situation', ';'), 'Nn']\n",
      "[('situation', ';', 'study'), 'Nn']\n",
      "[(';', 'study', 'about'), 'none']\n",
      "[('study', 'about', 'the'), 'none']\n",
      "[('about', 'the', 'leak'), 'none']\n",
      "[('the', 'leak', 'before'), 'none']\n",
      "[('leak', 'before', 'break'), 'none']\n",
      "[('before', 'break', '('), 'none']\n",
      "[('break', '(', 'lbb'), 'none']\n",
      "[('(', 'lbb', ')'), 'none']\n",
      "[('lbb', ')', 'technology'), 'none']\n",
      "[(')', 'technology', ';'), 'none']\n",
      "[('technology', ';', 'making'), 'Vform']\n",
      "[(';', 'making', 'model'), 'Vform']\n",
      "[('making', 'model', 'for'), 'Vform']\n",
      "[('model', 'for', 'vessel'), 'none']\n",
      "[('for', 'vessel', 'cooling'), 'none']\n",
      "[('vessel', 'cooling', 'system'), 'none']\n",
      "[('cooling', 'system', '('), 'none']\n",
      "[('system', '(', 'vcs'), 'none']\n",
      "[('(', 'vcs', ')'), 'none']\n",
      "[('vcs', ')', ';'), 'none']\n",
      "[(')', ';', 'analyses'), 'Vform']\n",
      "[(';', 'analyses', 'of'), 'Vform']\n",
      "[('analyses', 'of', 'the'), 'Vform']\n",
      "[('of', 'the', 'moment'), 'none']\n",
      "[('the', 'moment', 'when'), 'none']\n",
      "[('moment', 'when', '-'), 'ArtOrDet']\n",
      "[('when', '-', 'accident'), 'ArtOrDet']\n",
      "[('-', 'accident', 'happened'), 'ArtOrDet']\n",
      "[('accident', 'happened', ';'), 'none']\n",
      "[('happened', ';', '-'), 'V0']\n",
      "[(';', '-', 'safety'), 'V0']\n",
      "[('-', 'safety', 'aspects'), 'V0']\n",
      "[('safety', 'aspects', 'of'), 'none']\n",
      "[('aspects', 'of', 'the'), 'none']\n",
      "[('of', 'the', 'way'), 'Nn']\n",
      "[('the', 'way', 'how'), 'Nn']\n",
      "[('way', 'how', 'to'), 'Nn']\n",
      "[('how', 'to', 'combine'), 'Rloc-']\n",
      "[('to', 'combine', 'the'), 'none']\n",
      "[('combine', 'the', 'reactor'), 'none']\n",
      "[('the', 'reactor', 'to'), 'none']\n",
      "[('reactor', 'to', 'the'), 'none']\n",
      "[('to', 'the', 'hydrogen'), 'none']\n",
      "[('the', 'hydrogen', 'production'), 'none']\n",
      "[('hydrogen', 'production', 'plant'), 'none']\n",
      "[('pursing', 'patents', 'are'), 'Mec']\n",
      "[('patents', 'are', 'not'), 'SVA']\n",
      "[('are', 'not', 'easy'), 'SVA']\n",
      "[('not', 'easy', 'as'), 'none']\n",
      "[('easy', 'as', 'they'), 'none']\n",
      "[('as', 'they', 'will'), 'none']\n",
      "[('they', 'will', 'take'), 'none']\n",
      "[('will', 'take', 'long'), 'ArtOrDet']\n",
      "[('take', 'long', 'period'), 'ArtOrDet']\n",
      "[('long', 'period', 'of'), 'none']\n",
      "[('period', 'of', 'time'), 'none']\n",
      "[('of', 'time', 'to'), 'none']\n",
      "[('time', 'to', 'process'), 'none']\n",
      "[('to', 'process', ','), 'none']\n",
      "[('process', ',', 'requiring'), 'none']\n",
      "[(',', 'requiring', 'large'), 'none']\n",
      "[('requiring', 'large', 'amount'), 'none']\n",
      "[('large', 'amount', 'of'), 'none']\n",
      "[('amount', 'of', 'money'), 'none']\n",
      "[('critics', 'of', 'this'), 'none']\n",
      "[('of', 'this', 'proposal'), 'none']\n",
      "[('this', 'proposal', 'have'), 'none']\n",
      "[('proposal', 'have', 'pointed'), 'none']\n",
      "[('have', 'pointed', 'out'), 'Rloc-']\n",
      "[('pointed', 'out', 'that'), 'none']\n",
      "[('out', 'that', 'the'), 'none']\n",
      "[('that', 'the', 'money'), 'none']\n",
      "[('the', 'money', 'set'), 'none']\n",
      "[('money', 'set', 'aside'), 'none']\n",
      "[('set', 'aside', 'for'), 'none']\n",
      "[('aside', 'for', 'this'), 'none']\n",
      "[('for', 'this', 'scheme'), 'none']\n",
      "[('this', 'scheme', 'will'), 'none']\n",
      "[('scheme', 'will', 'go'), 'none']\n",
      "[('will', 'go', 'to'), 'none']\n",
      "[('go', 'to', 'waste'), 'none']\n",
      "[('to', 'waste', 'if'), 'none']\n",
      "[('waste', 'if', 'they'), 'Others']\n",
      "[('if', 'they', 'pass'), 'Others']\n",
      "[('they', 'pass', 'away'), 'Others']\n",
      "[('pass', 'away', 'even'), 'Vt']\n",
      "[('away', 'even', 'before'), 'none']\n",
      "[('even', 'before', 'they'), 'none']\n",
      "[('before', 'they', 'can'), 'none']\n",
      "[('they', 'can', 'utilize'), 'none']\n",
      "[('can', 'utilize', 'them'), 'none']\n",
      "[('when', 'people', 'get'), 'none']\n",
      "[('people', 'get', 'older'), 'none']\n",
      "[('get', 'older', ','), 'none']\n",
      "[('older', ',', 'it'), 'none']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 'it', 'is'), 'none']\n",
      "[('it', 'is', 'only'), 'none']\n",
      "[('is', 'only', 'natural'), 'none']\n",
      "[('only', 'natural', 'that'), 'none']\n",
      "[('natural', 'that', 'they'), 'none']\n",
      "[('that', 'they', 'are'), 'none']\n",
      "[('they', 'are', 'more'), 'none']\n",
      "[('are', 'more', 'prone'), 'none']\n",
      "[('more', 'prone', 'to'), 'none']\n",
      "[('prone', 'to', 'illness'), 'Nn']\n",
      "[('to', 'illness', 'be'), 'none']\n",
      "[('illness', 'be', 'it'), 'none']\n",
      "[('be', 'it', 'mentally'), 'Wform']\n",
      "[('it', 'mentally', 'or'), 'Wform']\n",
      "[('mentally', 'or', 'physically'), 'Wform']\n",
      "[('these', 'permit', 'the'), 'Pform']\n",
      "[('permit', 'the', 'aged'), 'SVA']\n",
      "[('the', 'aged', 'population'), 'none']\n",
      "[('aged', 'population', 'to'), 'none']\n",
      "[('population', 'to', 'continue'), 'none']\n",
      "[('to', 'continue', 'serving'), 'none']\n",
      "[('continue', 'serving', 'the'), 'ArtOrDet']\n",
      "[('serving', 'the', 'society'), 'ArtOrDet']\n",
      "[('the', 'society', 'and'), 'none']\n",
      "[('society', 'and', 'also'), 'none']\n",
      "[('and', 'also', 'in'), 'none']\n",
      "[('also', 'in', 'certain'), 'none']\n",
      "[('in', 'certain', 'ways'), 'none']\n",
      "[('certain', 'ways', 'help'), 'SVA']\n",
      "[('ways', 'help', 'to'), 'SVA']\n",
      "[('help', 'to', 'build'), 'SVA']\n",
      "[('to', 'build', 'confidence'), 'none']\n",
      "[('build', 'confidence', 'in'), 'none']\n",
      "[('confidence', 'in', 'the'), 'none']\n",
      "[('in', 'the', 'elderly'), 'none']\n",
      "[('however', ',', 'the'), 'none']\n",
      "[(',', 'the', 'two'), 'none']\n",
      "[('the', 'two', 'technologies'), 'none']\n",
      "[('two', 'technologies', 'are'), 'Vt']\n",
      "[('technologies', 'are', 'similar'), 'none']\n",
      "[('are', 'similar', 'in'), 'none']\n",
      "[('similar', 'in', 'these'), 'ArtOrDet']\n",
      "[('in', 'these', 'two'), 'ArtOrDet']\n",
      "[('these', 'two', 'stages'), 'ArtOrDet']\n",
      "[('two', 'stages', 'after'), 'ArtOrDet']\n",
      "[('stages', 'after', 'recognizing'), 'Rloc-']\n",
      "[('after', 'recognizing', 'a'), 'Rloc-']\n",
      "[('recognizing', 'a', 'problem'), 'Um']\n",
      "[('a', 'problem', 'or'), 'none']\n",
      "[('problem', 'or', 'need'), 'none']\n",
      "[('or', 'need', ':'), 'Rloc-']\n",
      "[('need', ':', '-'), 'Rloc-']\n",
      "[(':', '-', 'further'), 'Rloc-']\n",
      "[('-', 'further', 'research'), 'Rloc-']\n",
      "[('further', 'research', 'on'), 'WOinc']\n",
      "[('research', 'on', 'basic'), 'Rloc-']\n",
      "[('on', 'basic', 'and'), 'Rloc-']\n",
      "[('basic', 'and', 'application'), 'Rloc-']\n",
      "[('and', 'application', ','), 'Rloc-']\n",
      "[('application', ',', 'and'), 'Rloc-']\n",
      "[(',', 'and', 'development'), 'Rloc-']\n",
      "[('and', 'development', 'stages'), 'Rloc-']\n",
      "[('beside', 'the', 'lack'), 'none']\n",
      "[('the', 'lack', 'of'), 'none']\n",
      "[('lack', 'of', 'facilities'), 'none']\n",
      "[('of', 'facilities', ','), 'none']\n",
      "[('facilities', ',', 'engineers'), 'none']\n",
      "[(',', 'engineers', 'are'), 'none']\n",
      "[('engineers', 'are', 'constrain'), 'Vform']\n",
      "[('are', 'constrain', 'by'), 'Vform']\n",
      "[('constrain', 'by', 'the'), 'Vform']\n",
      "[('by', 'the', 'strict'), 'none']\n",
      "[('the', 'strict', 'regulatory'), 'Wform']\n",
      "[('strict', 'regulatory', 'imposed'), 'Wform']\n",
      "[('regulatory', 'imposed', 'by'), 'Wform']\n",
      "[('imposed', 'by', 'the'), 'none']\n",
      "[('by', 'the', 'governement'), 'none']\n",
      "[('thus', 'it', 'comes'), 'none']\n",
      "[('it', 'comes', 'as'), 'none']\n",
      "[('comes', 'as', 'no'), 'none']\n",
      "[('as', 'no', 'surprise'), 'none']\n",
      "[('no', 'surprise', 'that'), 'none']\n",
      "[('surprise', 'that', 'governments'), 'none']\n",
      "[('that', 'governments', 'around'), 'none']\n",
      "[('governments', 'around', 'the'), 'Rloc-']\n",
      "[('around', 'the', 'world'), 'none']\n",
      "[('the', 'world', 'have'), 'none']\n",
      "[('world', 'have', 'stepped'), 'none']\n",
      "[('have', 'stepped', 'up'), 'none']\n",
      "[('stepped', 'up', 'their'), 'none']\n",
      "[('up', 'their', 'efforts'), 'none']\n",
      "[('their', 'efforts', 'to'), 'none']\n",
      "[('efforts', 'to', 'alleviate'), 'none']\n",
      "[('to', 'alleviate', 'the'), 'none']\n",
      "[('alleviate', 'the', 'effects'), 'none']\n",
      "[('the', 'effects', 'of'), 'none']\n",
      "[('effects', 'of', 'global'), 'none']\n",
      "[('of', 'global', 'aging'), 'none']\n",
      "[('hopefully', ',', 'the'), 'none']\n",
      "[(',', 'the', 'next'), 'none']\n",
      "[('the', 'next', 'typical'), 'none']\n",
      "[('next', 'typical', 'image'), 'none']\n",
      "[('typical', 'image', 'left'), 'none']\n",
      "[('image', 'left', 'by'), 'none']\n",
      "[('left', 'by', 'china'), 'none']\n",
      "[('by', 'china', 'to'), 'none']\n",
      "[('china', 'to', 'the'), 'none']\n",
      "[('to', 'the', 'world'), 'none']\n",
      "[('the', 'world', 'will'), 'none']\n",
      "[('world', 'will', 'be'), 'none']\n",
      "[('will', 'be', '-'), 'none']\n",
      "[('be', '-', 'e-bike'), 'Others']\n",
      "[('-', 'iphone', 'now'), 'ArtOrDet']\n",
      "[('iphone', 'now', 'can'), 'Rloc-']\n",
      "[('now', 'can', 'serve'), 'Rloc-']\n",
      "[('can', 'serve', 'many'), 'none']\n",
      "[('serve', 'many', 'purposes'), 'Vt']\n",
      "[('many', 'purposes', 'of'), 'Vt']\n",
      "[('purposes', 'of', 'users'), 'Vt']\n",
      "[('of', 'users', 'like'), 'Vt']\n",
      "[('users', 'like', 'entertainment'), 'Vt']\n",
      "[('like', 'entertainment', ','), 'Trans']\n",
      "[('entertainment', ',', 'video'), 'Trans']\n",
      "[(',', 'video', 'conference'), 'Trans']\n",
      "[('apart', 'from', 'that'), 'none']\n",
      "[('from', 'that', ','), 'none']\n",
      "[('that', ',', 'it'), 'none']\n",
      "[(',', 'it', 'is'), 'none']\n",
      "[('it', 'is', 'well'), 'none']\n",
      "[('is', 'well', 'known'), 'none']\n",
      "[('well', 'known', 'how'), 'none']\n",
      "[('known', 'how', 'corrupted'), 'none']\n",
      "[('how', 'corrupted', 'the'), 'none']\n",
      "[('corrupted', 'the', 'country'), 'none']\n",
      "[('the', 'country', 'is'), 'none']\n",
      "[('or', 'is', 'it'), 'none']\n",
      "[('is', 'it', 'that'), 'none']\n",
      "[('it', 'that', 'it'), 'none']\n",
      "[('that', 'it', 'is'), 'none']\n",
      "[('it', 'is', 'a'), 'none']\n",
      "[('is', 'a', 'must'), 'none']\n",
      "[('a', 'must', 'to'), 'none']\n",
      "[('must', 'to', 'reveal'), 'none']\n",
      "[('to', 'reveal', 'it'), 'none']\n",
      "[('reveal', 'it', 'due'), 'none']\n",
      "[('it', 'due', 'to'), 'none']\n",
      "[('due', 'to', 'reality'), 'none']\n",
      "[('to', 'reality', 'and'), 'none']\n",
      "[('reality', 'and', 'we'), 'none']\n",
      "[('and', 'we', ','), 'none']\n",
      "[('we', ',', 'individual'), 'Nn']\n",
      "[(',', 'individual', 'do'), 'Nn']\n",
      "[('individual', 'do', 'not'), 'Nn']\n",
      "[('do', 'not', 'have'), 'none']\n",
      "[('not', 'have', 'the'), 'none']\n",
      "[('have', 'the', 'final'), 'none']\n",
      "[('the', 'final', 'say'), 'none']\n",
      "[('final', 'say', 'to'), 'none']\n",
      "[('say', 'to', 'reveal'), 'none']\n",
      "[('to', 'reveal', 'our'), 'none']\n",
      "[('reveal', 'our', 'testing'), 'none']\n",
      "[('our', 'testing', 'to'), 'none']\n",
      "[('testing', 'to', 'the'), 'none']\n",
      "[('to', 'the', 'public'), 'none']\n",
      "[('water', 'treatment', 'has'), 'SVA']\n",
      "[('treatment', 'has', 'largely'), 'SVA']\n",
      "[('has', 'largely', 'been'), 'SVA']\n",
      "[('largely', 'been', 'classified'), 'none']\n",
      "[('been', 'classified', 'as'), 'none']\n",
      "[('classified', 'as', 'one'), 'none']\n",
      "[('as', 'one', 'engineering'), 'none']\n",
      "[('one', 'engineering', 'process'), 'none']\n",
      "[('engineering', 'process', 'which'), 'none']\n",
      "[('process', 'which', 'turns'), 'none']\n",
      "[('which', 'turns', 'used-water'), 'none']\n",
      "[('turns', 'used-water', 'into'), 'none']\n",
      "[('used-water', 'into', 'clean'), 'none']\n",
      "[('into', 'clean', ','), 'none']\n",
      "[('clean', ',', 'acceptable'), 'none']\n",
      "[(',', 'acceptable', 'water'), 'none']\n",
      "[('acceptable', 'water', 'for'), 'none']\n",
      "[('water', 'for', 'end'), 'none']\n",
      "[('for', 'end', 'use'), 'none']\n",
      "[('end', 'use', ','), 'none']\n",
      "[('use', ',', 'and'), 'none']\n",
      "[(',', 'and', 'sometime'), 'none']\n",
      "[('and', 'sometime', 'even'), 'none']\n",
      "[('sometime', 'even', 'drinkable'), 'none']\n",
      "[('even', 'drinkable', 'water'), 'none']\n",
      "[('the', 'repercussions', 'following'), 'none']\n",
      "[('repercussions', 'following', 'the'), 'none']\n",
      "[('following', 'the', 'aging'), 'none']\n",
      "[('the', 'aging', 'population'), 'none']\n",
      "[('aging', 'population', 'would'), 'none']\n",
      "[('population', 'would', 'be'), 'none']\n",
      "[('would', 'be', 'social'), 'none']\n",
      "[('be', 'social', 'and'), 'none']\n",
      "[('social', 'and', 'economy'), 'Wform']\n",
      "[('and', 'economy', 'concerns'), 'Wform']\n",
      "[('economy', 'concerns', 'as'), 'Wform']\n",
      "[('concerns', 'as', 'the'), 'none']\n",
      "[('as', 'the', 'younger'), 'none']\n",
      "[('the', 'younger', 'generations'), 'none']\n",
      "[('younger', 'generations', 'would'), 'none']\n",
      "[('generations', 'would', 'have'), 'none']\n",
      "[('would', 'have', 'to'), 'none']\n",
      "[('have', 'to', 'struggle'), 'none']\n",
      "[('to', 'struggle', 'to'), 'none']\n",
      "[('struggle', 'to', 'support'), 'none']\n",
      "[('to', 'support', 'their'), 'none']\n",
      "[('support', 'their', 'families'), 'none']\n",
      "[('the', 'burden', 'on'), 'none']\n",
      "[('burden', 'on', 'an'), 'none']\n",
      "[('on', 'an', 'average'), 'none']\n",
      "[('an', 'average', 'working'), 'none']\n",
      "[('average', 'working', 'class'), 'none']\n",
      "[('working', 'class', 'adult'), 'none']\n",
      "[('class', 'adult', 'has'), 'none']\n",
      "[('adult', 'has', 'been'), 'Vt']\n",
      "[('has', 'been', 'increasing'), 'Vt']\n",
      "[('been', 'increasing', 'with'), 'Vt']\n",
      "[('increasing', 'with', 'yearly'), 'Vt']\n",
      "[('with', 'yearly', 'inflation'), 'none']\n",
      "[('yearly', 'inflation', 'and'), 'none']\n",
      "[('inflation', 'and', 'higher'), 'none']\n",
      "[('and', 'higher', 'standards'), 'none']\n",
      "[('higher', 'standards', 'of'), 'none']\n",
      "[('standards', 'of', 'living'), 'Nn']\n",
      "[('engineers', 'have', 'brought'), 'Wci']\n",
      "[('have', 'brought', 'out'), 'Wci']\n",
      "[('brought', 'out', 'some'), 'Wci']\n",
      "[('out', 'some', 'solutions'), 'Wci']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('some', 'solutions', 'for'), 'Mec']\n",
      "[('solutions', 'for', 'saving'), 'Mec']\n",
      "[('for', 'saving', 'the'), 'ArtOrDet']\n",
      "[('saving', 'the', 'petroleum'), 'ArtOrDet']\n",
      "[('one', 'step', 'that'), 'none']\n",
      "[('step', 'that', 'can'), 'Vt']\n",
      "[('that', 'can', 'be'), 'none']\n",
      "[('can', 'be', 'taken'), 'none']\n",
      "[('be', 'taken', 'would'), 'Vt']\n",
      "[('taken', 'would', 'be'), 'none']\n",
      "[('would', 'be', 'to'), 'none']\n",
      "[('be', 'to', 'remove'), 'none']\n",
      "[('to', 'remove', 'sharp'), 'none']\n",
      "[('remove', 'sharp', '148-'), 'Vt']\n",
      "[('sharp', '148-', 'degree'), 'Vt']\n",
      "[('148-', 'degree', 'turns'), 'Vt']\n",
      "[('degree', 'turns', 'that'), 'Vt']\n",
      "[('turns', 'that', 'the'), 'none']\n",
      "[('that', 'the', 'pa1736'), 'none']\n",
      "[('the', 'pa1736', ','), 'none']\n",
      "[('pa1736', ',', 'a'), 'none']\n",
      "[(',', 'a', '747'), 'none']\n",
      "[('a', '747', ','), 'none']\n",
      "[('747', ',', 'would'), 'none']\n",
      "[(',', 'would', 'not'), 'none']\n",
      "[('would', 'not', 'be'), 'none']\n",
      "[('not', 'be', 'able'), 'none']\n",
      "[('be', 'able', 'to'), 'none']\n",
      "[('able', 'to', 'take'), 'none']\n",
      "[('basically', 'set', 'up'), 'Sfrag']\n",
      "[('set', 'up', 'a'), 'none']\n",
      "[('up', 'a', 'healthier'), 'none']\n",
      "[('a', 'healthier', 'financial'), 'none']\n",
      "[('healthier', 'financial', 'saving'), 'none']\n",
      "[('financial', 'saving', 'system'), 'none']\n",
      "[('saving', 'system', 'according'), 'Um']\n",
      "[('system', 'according', 'to'), 'Um']\n",
      "[('according', 'to', 'different'), 'Um']\n",
      "[('to', 'different', 'period'), 'Um']\n",
      "[('different', 'period', 'the'), 'Um']\n",
      "[('period', 'the', 'different'), 'Um']\n",
      "[('the', 'different', 'economic'), 'Um']\n",
      "[('different', 'economic', 'situation'), 'Um']\n",
      "[('economic', 'situation', 'with'), 'Um']\n",
      "[('situation', 'with', 'proper'), 'Um']\n",
      "[('with', 'proper', 'interest'), 'Um']\n",
      "[('proper', 'interest', 'rate'), 'Um']\n",
      "[('interest', 'rate', 'and'), 'Um']\n",
      "[('rate', 'and', 'bonus'), 'Um']\n",
      "[('on', 'the', 'other'), 'none']\n",
      "[('the', 'other', 'hand'), 'none']\n",
      "[('other', 'hand', ','), 'none']\n",
      "[('hand', ',', 'apple'), 'none']\n",
      "[(',', 'apple', 'has'), 'none']\n",
      "[('apple', 'has', 'also'), 'none']\n",
      "[('has', 'also', 'release'), 'none']\n",
      "[('also', 'release', 'its'), 'none']\n",
      "[('release', 'its', 'highly'), 'none']\n",
      "[('its', 'highly', 'portable'), 'none']\n",
      "[('highly', 'portable', 'laptop'), 'none']\n",
      "[('portable', 'laptop', 'called'), 'none']\n",
      "[('laptop', 'called', 'macbook'), 'none']\n",
      "[('called', 'macbook', 'pro'), 'none']\n",
      "[('macbook', 'pro', 'which'), 'none']\n",
      "[('pro', 'which', 'is'), 'none']\n",
      "[('which', 'is', 'the'), 'none']\n",
      "[('is', 'the', 'thinnest'), 'none']\n",
      "[('the', 'thinnest', '17-inch'), 'none']\n",
      "[('thinnest', '17-inch', 'laptop'), 'none']\n",
      "[('17-inch', 'laptop', 'in'), 'none']\n",
      "[('laptop', 'in', 'the'), 'none']\n",
      "[('in', 'the', 'world'), 'none']\n",
      "[('however', ',', 'the'), 'none']\n",
      "[(',', 'the', '3m'), 'none']\n",
      "[('the', '3m', 'researchers'), 'none']\n",
      "[('3m', 'researchers', 'found'), 'none']\n",
      "[('researchers', 'found', 'out'), 'Wci']\n",
      "[('found', 'out', 'this'), 'Wci']\n",
      "[('out', 'this', 'failed'), 'Wci']\n",
      "[('this', 'failed', 'bonding'), 'none']\n",
      "[('failed', 'bonding', 'agent'), 'none']\n",
      "[('bonding', 'agent', 'was'), 'none']\n",
      "[('agent', 'was', 'suitable'), 'none']\n",
      "[('was', 'suitable', 'for'), 'none']\n",
      "[('suitable', 'for', 'attaching'), 'none']\n",
      "[('for', 'attaching', 'notes'), 'none']\n",
      "[('attaching', 'notes', 'which'), 'none']\n",
      "[('notes', 'which', 'satisfy'), 'Vt']\n",
      "[('which', 'satisfy', 'many'), 'Vt']\n",
      "[('satisfy', 'many', 'people'), 'Vt']\n",
      "[('many', 'people', \"'s\"), 'none']\n",
      "[('people', \"'s\", 'needs'), 'none']\n",
      "[('besides', 'that', ','), 'none']\n",
      "[('that', ',', 'the'), 'none']\n",
      "[(',', 'the', 'cpf'), 'none']\n",
      "[('the', 'cpf', 'can'), 'none']\n",
      "[('cpf', 'can', 'also'), 'none']\n",
      "[('can', 'also', 'be'), 'none']\n",
      "[('also', 'be', 'used'), 'none']\n",
      "[('be', 'used', 'to'), 'none']\n",
      "[('used', 'to', 'buy'), 'none']\n",
      "[('to', 'buy', 'a'), 'none']\n",
      "[('buy', 'a', 'house'), 'none']\n",
      "[('a', 'house', ','), 'none']\n",
      "[('house', ',', 'cover'), 'none']\n",
      "[(',', 'cover', 'hospital'), 'none']\n",
      "[('cover', 'hospital', 'expenses'), 'none']\n",
      "[('hospital', 'expenses', 'or'), 'none']\n",
      "[('expenses', 'or', 'for'), 'none']\n",
      "[('or', 'for', 'child'), 'Rloc-']\n",
      "[('for', 'child', \"'s\"), 'Rloc-']\n",
      "[('child', \"'s\", 'education'), 'Rloc-']\n",
      "[(\"'s\", 'education', 'fees'), 'Rloc-']\n",
      "[('however', 'taking', 'a'), 'none']\n",
      "[('taking', 'a', 'look'), 'Smod']\n",
      "[('a', 'look', 'around'), 'Smod']\n",
      "[('look', 'around', 'us'), 'none']\n",
      "[('around', 'us', 'today'), 'none']\n",
      "[('us', 'today', ','), 'none']\n",
      "[('today', ',', 'current'), 'none']\n",
      "[(',', 'current', 'research'), 'none']\n",
      "[('current', 'research', ','), 'SVA']\n",
      "[('research', ',', 'development'), 'none']\n",
      "[(',', 'development', 'and'), 'none']\n",
      "[('development', 'and', 'various'), 'none']\n",
      "[('and', 'various', 'policies'), 'none']\n",
      "[('various', 'policies', 'have'), 'none']\n",
      "[('policies', 'have', 'evolved'), 'none']\n",
      "[('have', 'evolved', 'to'), 'none']\n",
      "[('evolved', 'to', 'an'), 'none']\n",
      "[('to', 'an', 'extent'), 'Um']\n",
      "[('an', 'extent', 'large'), 'none']\n",
      "[('extent', 'large', 'enough'), 'none']\n",
      "[('large', 'enough', 'to'), 'none']\n",
      "[('enough', 'to', 'dismiss'), 'none']\n",
      "[('to', 'dismiss', 'our'), 'Wtone']\n",
      "[('dismiss', 'our', 'concerns'), 'Wtone']\n",
      "[('our', 'concerns', 'with'), 'Prep']\n",
      "[('concerns', 'with', 'a'), 'Prep']\n",
      "[('with', 'a', 'greying'), 'Prep']\n",
      "[('a', 'greying', 'population'), 'none']\n",
      "[('but', 'on', 'the'), 'none']\n",
      "[('on', 'the', 'other'), 'none']\n",
      "[('the', 'other', 'hand'), 'none']\n",
      "[('other', 'hand', ','), 'none']\n",
      "[('hand', ',', 'not'), 'none']\n",
      "[(',', 'not', 'all'), 'none']\n",
      "[('not', 'all', 'factors'), 'none']\n",
      "[('all', 'factors', 'are'), 'none']\n",
      "[('factors', 'are', 'within'), 'none']\n",
      "[('are', 'within', 'the'), 'none']\n",
      "[('within', 'the', 'control'), 'none']\n",
      "[('the', 'control', 'of'), 'none']\n",
      "[('control', 'of', 'human'), 'none']\n",
      "[('of', 'human', \"'s\"), 'ArtOrDet']\n",
      "[('human', \"'s\", 'capability'), 'Wform']\n",
      "[('at', 'that', 'point'), 'none']\n",
      "[('that', 'point', ','), 'none']\n",
      "[('point', ',', 'trevor'), 'none']\n",
      "[(',', 'trevor', 'baylis'), 'none']\n",
      "[('trevor', 'baylis', 'came'), 'none']\n",
      "[('baylis', 'came', 'up'), 'none']\n",
      "[('came', 'up', 'with'), 'none']\n",
      "[('up', 'with', 'the'), 'none']\n",
      "[('with', 'the', 'idea'), 'none']\n",
      "[('the', 'idea', 'of'), 'none']\n",
      "[('idea', 'of', '-'), 'ArtOrDet']\n",
      "[('of', '-', 'wind-up'), 'ArtOrDet']\n",
      "[('-', 'wind-up', 'radio'), 'ArtOrDet']\n",
      "[('wind-up', 'radio', ','), 'none']\n",
      "[('radio', ',', 'making'), 'none']\n",
      "[(',', 'making', '-'), 'ArtOrDet']\n",
      "[('making', '-', 'idea'), 'ArtOrDet']\n",
      "[('-', 'idea', 'of'), 'ArtOrDet']\n",
      "[('idea', 'of', 'broadcasting'), 'none']\n",
      "[('of', 'broadcasting', 'education'), 'none']\n",
      "[('broadcasting', 'education', 'possible'), 'none']\n",
      "[('in', 'addition', 'to'), 'none']\n",
      "[('addition', 'to', 'that'), 'none']\n",
      "[('to', 'that', ','), 'none']\n",
      "[('that', ',', 'the'), 'none']\n",
      "[(',', 'the', 'money'), 'none']\n",
      "[('the', 'money', 'that'), 'none']\n",
      "[('money', 'that', 'is'), 'none']\n",
      "[('that', 'is', 'spent'), 'none']\n",
      "[('is', 'spent', 'to'), 'Wci']\n",
      "[('spent', 'to', 'help'), 'Wci']\n",
      "[('to', 'help', 'the'), 'none']\n",
      "[('help', 'the', 'elderly'), 'none']\n",
      "[('the', 'elderly', 'is'), 'none']\n",
      "[('elderly', 'is', 'partially'), 'none']\n",
      "[('is', 'partially', 'their'), 'none']\n",
      "[('partially', 'their', 'money'), 'none']\n",
      "[('their', 'money', 'which'), 'none']\n",
      "[('money', 'which', 'was'), 'none']\n",
      "[('which', 'was', 'deducted'), 'none']\n",
      "[('was', 'deducted', 'through'), 'none']\n",
      "[('deducted', 'through', 'tax'), 'none']\n",
      "[('through', 'tax', 'payment'), 'none']\n",
      "[('this', 'is', 'not'), 'none']\n",
      "[('is', 'not', 'true'), 'none']\n",
      "[('not', 'true', 'as'), 'none']\n",
      "[('true', 'as', 'the'), 'none']\n",
      "[('as', 'the', 'vhtr'), 'none']\n",
      "[('the', 'vhtr', 'is'), 'none']\n",
      "[('vhtr', 'is', 'developing'), 'none']\n",
      "[('is', 'developing', 'a'), 'none']\n",
      "[('developing', 'a', 'passive'), 'none']\n",
      "[('a', 'passive', 'heat'), 'none']\n",
      "[('passive', 'heat', 'removal'), 'none']\n",
      "[('heat', 'removal', 'system'), 'none']\n",
      "[('removal', 'system', 'that'), 'none']\n",
      "[('system', 'that', 'could'), 'Vt']\n",
      "[('that', 'could', 'achieve'), 'Vt']\n",
      "[('could', 'achieve', 'a'), 'Vt']\n",
      "[('achieve', 'a', 'higher'), 'none']\n",
      "[('a', 'higher', 'level'), 'none']\n",
      "[('higher', 'level', 'of'), 'Um']\n",
      "[('level', 'of', 'safety'), 'none']\n",
      "[('of', 'safety', 'which'), 'none']\n",
      "[('safety', 'which', 'is'), 'none']\n",
      "[('which', 'is', 'not'), 'none']\n",
      "[('is', 'not', 'dependent'), 'none']\n",
      "[('not', 'dependent', 'on'), 'none']\n",
      "[('dependent', 'on', 'human'), 'none']\n",
      "[('on', 'human', \"'s\"), 'Npos']\n",
      "[('human', \"'s\", 'intervention'), 'Wform']\n",
      "[('hence', ',', 'in'), 'none']\n",
      "[(',', 'in', 'future'), 'none']\n",
      "[('in', 'future', ','), 'none']\n",
      "[('future', ',', 'when'), 'none']\n",
      "[(',', 'when', 'migration'), 'none']\n",
      "[('when', 'migration', 'issue'), 'Nn']\n",
      "[('migration', 'issue', 'becomes'), 'Nn']\n",
      "[('issue', 'becomes', 'a'), 'Nn']\n",
      "[('becomes', 'a', 'global'), 'none']\n",
      "[('a', 'global', 'pandemic'), 'none']\n",
      "[('global', 'pandemic', ','), 'none']\n",
      "[('pandemic', ',', '-'), 'ArtOrDet']\n",
      "[(',', '-', 'public'), 'ArtOrDet']\n",
      "[('-', 'public', 'should'), 'ArtOrDet']\n",
      "[('public', 'should', 'give'), 'none']\n",
      "[('should', 'give', 'a'), 'none']\n",
      "[('give', 'a', 'helping'), 'none']\n",
      "[('a', 'helping', 'hand'), 'none']\n",
      "[('helping', 'hand', 'to'), 'none']\n",
      "[('hand', 'to', 'the'), 'none']\n",
      "[('to', 'the', 'aged'), 'none']\n",
      "[('the', 'aged', 'since'), 'Wci']\n",
      "[('aged', 'since', 'the'), 'none']\n",
      "[('since', 'the', 'children'), 'none']\n",
      "[('the', 'children', 'will'), 'none']\n",
      "[('children', 'will', 'no'), 'none']\n",
      "[('will', 'no', 'longer'), 'none']\n",
      "[('no', 'longer', 'take'), 'none']\n",
      "[('longer', 'take', 'care'), 'none']\n",
      "[('take', 'care', 'of'), 'none']\n",
      "[('care', 'of', 'his'), 'Pform']\n",
      "[('of', 'his', 'needs'), 'Pform']\n",
      "[('an', 'example', 'could'), 'none']\n",
      "[('example', 'could', 'be'), 'Vform']\n",
      "[('could', 'be', 'seen'), 'none']\n",
      "[('be', 'seen', 'in'), 'none']\n",
      "[('seen', 'in', 'the'), 'none']\n",
      "[('in', 'the', 'following'), 'none']\n",
      "[('the', 'following', 'article'), 'Prep']\n",
      "[('following', 'article', 'which'), 'Prep']\n",
      "[('article', 'which', 'writes'), 'Prep']\n",
      "[('which', 'writes', '``'), 'Prep']\n",
      "[('writes', '``', 'is'), 'none']\n",
      "[('``', 'is', \"n't\"), 'none']\n",
      "[('is', \"n't\", 'the'), 'none']\n",
      "[(\"n't\", 'the', 'hdb'), 'none']\n",
      "[('the', 'hdb', \"'s\"), 'none']\n",
      "[('hdb', \"'s\", 'policies'), 'none']\n",
      "[(\"'s\", 'policies', 'self-contradictory'), 'none']\n",
      "[('policies', 'self-contradictory', ','), 'none']\n",
      "[('self-contradictory', ',', 'when'), 'none']\n",
      "[(',', 'when', 'it'), 'none']\n",
      "[('when', 'it', \"'s\"), 'none']\n",
      "[('it', \"'s\", 'income'), 'none']\n",
      "[(\"'s\", 'income', 'ceiling'), 'none']\n",
      "[('income', 'ceiling', 'policy'), 'none']\n",
      "[('ceiling', 'policy', \"'forces\"), 'none']\n",
      "[('policy', \"'forces\", \"'\"), 'none']\n",
      "[(\"'forces\", \"'\", 'the'), 'none']\n",
      "[(\"'\", 'the', 'lower-income'), 'none']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 'lower-income', 'to'), 'none']\n",
      "[('lower-income', 'to', 'buy'), 'none']\n",
      "[('to', 'buy', 'larger'), 'none']\n",
      "[('buy', 'larger', 'flats'), 'none']\n",
      "[('larger', 'flats', 'than'), 'none']\n",
      "[('flats', 'than', 'they'), 'none']\n",
      "[('than', 'they', 'can'), 'none']\n",
      "[('they', 'can', 'afford'), 'none']\n",
      "[('can', 'afford', '...'), 'none']\n",
      "[('afford', '...', 'hdb'), 'none']\n",
      "[('...', 'hdb', \"'s\"), 'none']\n",
      "[('hdb', \"'s\", 'income'), 'none']\n",
      "[(\"'s\", 'income', 'eligibility'), 'none']\n",
      "[('income', 'eligibility', 'requires'), 'none']\n",
      "[('eligibility', 'requires', 'a'), 'none']\n",
      "[('requires', 'a', 'household'), 'none']\n",
      "[('a', 'household', 'earning'), 'none']\n",
      "[('household', 'earning', 'more'), 'none']\n",
      "[('earning', 'more', 'than'), 'none']\n",
      "[('more', 'than', '$'), 'none']\n",
      "[('than', '$', '2,000'), 'none']\n",
      "[('$', '2,000', 'a'), 'none']\n",
      "[('2,000', 'a', 'month'), 'none']\n",
      "[('a', 'month', 'to'), 'none']\n",
      "[('month', 'to', 'buy'), 'none']\n",
      "[('to', 'buy', 'a'), 'none']\n",
      "[('buy', 'a', 'flat'), 'none']\n",
      "[('a', 'flat', 'that'), 'none']\n",
      "[('flat', 'that', 'is'), 'SVA']\n",
      "[('that', 'is', 'bigger'), 'none']\n",
      "[('is', 'bigger', 'than'), 'none']\n",
      "[('bigger', 'than', 'a'), 'none']\n",
      "[('than', 'a', 'two-room'), 'none']\n",
      "[('a', 'two-room', 'flat'), 'none']\n",
      "[('two-room', 'flat', '...'), 'none']\n",
      "[('flat', '...', 'a'), 'none']\n",
      "[('...', 'a', 'household'), 'none']\n",
      "[('a', 'household', 'earning'), 'none']\n",
      "[('household', 'earning', 'just'), 'none']\n",
      "[('earning', 'just', 'over'), 'none']\n",
      "[('just', 'over', '$'), 'none']\n",
      "[('over', '$', '3,000'), 'none']\n",
      "[('$', '3,000', ','), 'none']\n",
      "[('3,000', ',', 'is'), 'none']\n",
      "[(',', 'is', 'also'), 'Rloc-']\n",
      "[('is', 'also', 'not'), 'none']\n",
      "[('also', 'not', 'eligible'), 'none']\n",
      "[('not', 'eligible', 'to'), 'none']\n",
      "[('eligible', 'to', 'buy'), 'none']\n",
      "[('to', 'buy', 'a'), 'none']\n",
      "[('buy', 'a', 'three-room'), 'none']\n",
      "[('a', 'three-room', 'flat'), 'none']\n",
      "[('three-room', 'flat', ','), 'none']\n",
      "[('flat', ',', 'and'), 'none']\n",
      "[(',', 'and', 'have'), 'none']\n",
      "[('and', 'have', 'to'), 'none']\n",
      "[('have', 'to', 'buy'), 'none']\n",
      "[('to', 'buy', 'a'), 'none']\n",
      "[('buy', 'a', 'four-room'), 'none']\n",
      "[('a', 'four-room', 'flat'), 'none']\n",
      "[('thus', ',', 'it'), 'none']\n",
      "[(',', 'it', 'is'), 'none']\n",
      "[('it', 'is', 'fair'), 'none']\n",
      "[('is', 'fair', 'to'), 'none']\n",
      "[('fair', 'to', 'say'), 'none']\n",
      "[('to', 'say', 'that'), 'none']\n",
      "[('say', 'that', 'either'), 'Trans']\n",
      "[('that', 'either', 'conventional'), 'Trans']\n",
      "[('either', 'conventional', 'technology'), 'Trans']\n",
      "[('conventional', 'technology', 'or'), 'none']\n",
      "[('technology', 'or', 'serendipitous'), 'none']\n",
      "[('or', 'serendipitous', 'technology'), 'none']\n",
      "[('serendipitous', 'technology', 'is'), 'none']\n",
      "[('technology', 'is', 'stimulated'), 'SVA']\n",
      "[('is', 'stimulated', 'by'), 'SVA']\n",
      "[('stimulated', 'by', 'the'), 'none']\n",
      "[('by', 'the', 'realization'), 'none']\n",
      "[('the', 'realization', 'of'), 'none']\n",
      "[('realization', 'of', 'problems'), 'none']\n",
      "[('of', 'problems', 'and'), 'none']\n",
      "[('problems', 'and', 'needs'), 'none']\n",
      "[('as', 'the', 'country'), 'none']\n",
      "[('the', 'country', 'will'), 'none']\n",
      "[('country', 'will', 'have'), 'Vt']\n",
      "[('will', 'have', 'less'), 'Wci']\n",
      "[('have', 'less', 'working'), 'Wform']\n",
      "[('less', 'working', 'force'), 'Wform']\n",
      "[('working', 'force', 'in'), 'Wform']\n",
      "[('force', 'in', '2030'), 'none']\n",
      "[('in', '2030', ','), 'none']\n",
      "[('2030', ',', 'the'), 'none']\n",
      "[(',', 'the', 'government'), 'none']\n",
      "[('the', 'government', 'should'), 'none']\n",
      "[('government', 'should', 'invest'), 'none']\n",
      "[('should', 'invest', 'more'), 'none']\n",
      "[('invest', 'more', 'money'), 'Rloc-']\n",
      "[('more', 'money', 'on'), 'none']\n",
      "[('money', 'on', 'education'), 'none']\n",
      "[('on', 'education', 'to'), 'none']\n",
      "[('education', 'to', 'obtain'), 'none']\n",
      "[('to', 'obtain', 'a'), 'Wci']\n",
      "[('obtain', 'a', 'stronger'), 'none']\n",
      "[('a', 'stronger', 'working'), 'Wform']\n",
      "[('stronger', 'working', 'force'), 'Wform']\n",
      "[('working', 'force', 'to'), 'Wform']\n",
      "[('force', 'to', 'support'), 'none']\n",
      "[('to', 'support', 'the'), 'none']\n",
      "[('support', 'the', 'country'), 'none']\n",
      "[('the', 'country', 'and'), 'none']\n",
      "[('country', 'and', 'the'), 'none']\n",
      "[('and', 'the', 'large'), 'none']\n",
      "[('the', 'large', 'group'), 'none']\n",
      "[('large', 'group', 'of'), 'none']\n",
      "[('group', 'of', 'elderly'), 'none']\n",
      "[('for', '-', 'bionic'), 'ArtOrDet']\n",
      "[('-', 'bionic', 'eyes'), 'ArtOrDet']\n",
      "[('bionic', 'eyes', ','), 'none']\n",
      "[('eyes', ',', 'it'), 'Rloc-']\n",
      "[(',', 'it', 'was'), 'none']\n",
      "[('it', 'was', 'done'), 'Um']\n",
      "[('was', 'done', 'via'), 'none']\n",
      "[('done', 'via', 'research'), 'none']\n",
      "[('via', 'research', 'after'), 'none']\n",
      "[('research', 'after', 'seeing'), 'Sfrag']\n",
      "[('after', 'seeing', 'it'), 'Sfrag']\n",
      "[('seeing', 'it', 'in'), 'Sfrag']\n",
      "[('it', 'in', 'a'), 'Sfrag']\n",
      "[('in', 'a', 'movie'), 'none']\n",
      "[('a', 'movie', 'called'), 'none']\n",
      "[('movie', 'called', \"'terminator\"), 'none']\n",
      "[('called', \"'terminator\", \"'\"), 'none']\n",
      "[(\"'terminator\", \"'\", ','), 'none']\n",
      "[(\"'\", ',', 'where'), 'none']\n",
      "[(',', 'where', 'a'), 'Srun']\n",
      "[('where', 'a', 'woman'), 'none']\n",
      "[('a', 'woman', 'is'), 'none']\n",
      "[('woman', 'is', 'able'), 'none']\n",
      "[('is', 'able', 'to'), 'none']\n",
      "[('able', 'to', 'zoom'), 'none']\n",
      "[('to', 'zoom', 'on'), 'Prep']\n",
      "[('zoom', 'on', 'places'), 'Prep']\n",
      "[('on', 'places', 'that'), 'Prep']\n",
      "[('places', 'that', 'are'), 'none']\n",
      "[('that', 'are', 'far'), 'none']\n",
      "[('are', 'far', 'away'), 'none']\n",
      "[('as', 'a', 'result'), 'none']\n",
      "[('a', 'result', ','), 'none']\n",
      "[('result', ',', 'many'), 'Rloc-']\n",
      "[(',', 'many', 'students'), 'none']\n",
      "[('many', 'students', 'get'), 'none']\n",
      "[('students', 'get', 'used'), 'none']\n",
      "[('get', 'used', 'to'), 'none']\n",
      "[('used', 'to', 'accepting'), 'none']\n",
      "[('to', 'accepting', 'the'), 'ArtOrDet']\n",
      "[('accepting', 'the', 'information'), 'ArtOrDet']\n",
      "[('the', 'information', 'in'), 'ArtOrDet']\n",
      "[('information', 'in', 'the'), 'Um']\n",
      "[('in', 'the', 'references'), 'Um']\n",
      "[('the', 'references', 'without'), 'Um']\n",
      "[('references', 'without', 'thinking'), 'Um']\n",
      "[('without', 'thinking', 'and'), 'none']\n",
      "[('thinking', 'and', 'investigating'), 'none']\n",
      "[('and', 'investigating', 'by'), 'none']\n",
      "[('investigating', 'by', 'themselves'), 'none']\n",
      "[('with', 'this', 'kind'), 'none']\n",
      "[('this', 'kind', 'of'), 'none']\n",
      "[('kind', 'of', 'hydrogen'), 'none']\n",
      "[('of', 'hydrogen', 'energy'), 'none']\n",
      "[('hydrogen', 'energy', ','), 'none']\n",
      "[('energy', ',', 'a'), 'none']\n",
      "[(',', 'a', 'lot'), 'none']\n",
      "[('a', 'lot', 'of'), 'none']\n",
      "[('lot', 'of', 'problems'), 'none']\n",
      "[('of', 'problems', 'that'), 'Wtone']\n",
      "[('problems', 'that', 'obese'), 'none']\n",
      "[('that', 'obese', 'us'), 'none']\n",
      "[('obese', 'us', 'today'), 'none']\n",
      "[('us', 'today', 'will'), 'none']\n",
      "[('today', 'will', 'be'), 'none']\n",
      "[('will', 'be', 'solved.no'), 'none']\n",
      "[('be', 'solved.no', 'wars'), 'none']\n",
      "[('solved.no', 'wars', 'for'), 'none']\n",
      "[('wars', 'for', 'energy'), 'none']\n",
      "[('for', 'energy', 'will'), 'none']\n",
      "[('energy', 'will', 'break'), 'none']\n",
      "[('there', 'are', 'the'), 'ArtOrDet']\n",
      "[('are', 'the', 'architectural'), 'none']\n",
      "[('the', 'architectural', ','), 'none']\n",
      "[('architectural', ',', 'biomedical'), 'none']\n",
      "[(',', 'biomedical', ','), 'none']\n",
      "[('biomedical', ',', 'civil'), 'none']\n",
      "[(',', 'civil', ','), 'none']\n",
      "[('civil', ',', 'computer'), 'none']\n",
      "[(',', 'computer', ','), 'none']\n",
      "[('computer', ',', 'electrical'), 'none']\n",
      "[(',', 'electrical', ','), 'none']\n",
      "[('electrical', ',', 'industrial'), 'none']\n",
      "[(',', 'industrial', ','), 'none']\n",
      "[('industrial', ',', 'mechanical'), 'none']\n",
      "[(',', 'mechanical', 'and'), 'none']\n",
      "[('mechanical', 'and', 'software'), 'none']\n",
      "[('and', 'software', 'engineering'), 'none']\n",
      "[('moreover', ',', 'for'), 'none']\n",
      "[(',', 'for', 'the'), 'none']\n",
      "[('for', 'the', 'generation'), 'none']\n",
      "[('the', 'generation', '('), 'none']\n",
      "[('generation', '(', 'iv'), 'none']\n",
      "[('(', 'iv', ')'), 'none']\n",
      "[('iv', ')', 'reactors'), 'none']\n",
      "[(')', 'reactors', ','), 'none']\n",
      "[('reactors', ',', 'there'), 'none']\n",
      "[(',', 'there', 'is'), 'none']\n",
      "[('there', 'is', 'a'), 'none']\n",
      "[('is', 'a', 'debate'), 'none']\n",
      "[('a', 'debate', '-'), 'Others']\n",
      "[('debate', '-', 'to'), 'Others']\n",
      "[('-', 'to', 'channel'), 'Others']\n",
      "[('to', 'channel', 'the'), 'none']\n",
      "[('channel', 'the', 'funds'), 'none']\n",
      "[('the', 'funds', 'for'), 'none']\n",
      "[('funds', 'for', 'the'), 'none']\n",
      "[('for', 'the', 'research'), 'none']\n",
      "[('the', 'research', 'of'), 'none']\n",
      "[('research', 'of', 'supercritical'), 'none']\n",
      "[('of', 'supercritical', 'water'), 'none']\n",
      "[('supercritical', 'water', 'reactors'), 'none']\n",
      "[('water', 'reactors', '('), 'none']\n",
      "[('reactors', '(', 'scwr'), 'none']\n",
      "[('(', 'scwr', ')'), 'none']\n",
      "[('scwr', ')', ','), 'none']\n",
      "[(')', ',', 'which'), 'none']\n",
      "[(',', 'which', 'is'), 'none']\n",
      "[('which', 'is', 'claimed'), 'WOinc']\n",
      "[('is', 'claimed', 'by'), 'WOinc']\n",
      "[('claimed', 'by', 'scientists'), 'WOinc']\n",
      "[('by', 'scientists', 'that'), 'WOinc']\n",
      "[('scientists', 'that', 'it'), 'Rloc-']\n",
      "[('that', 'it', 'would'), 'Rloc-']\n",
      "[('it', 'would', 'benefit'), 'Rloc-']\n",
      "[('would', 'benefit', 'mankind'), 'none']\n",
      "[('benefit', 'mankind', 'more'), 'none']\n",
      "[('mankind', 'more', 'in'), 'none']\n",
      "[('more', 'in', 'most'), 'none']\n",
      "[('in', 'most', 'aspects'), 'none']\n",
      "[('most', 'aspects', 'considered'), 'Rloc-']\n",
      "[('aspects', 'considered', 'like'), 'Rloc-']\n",
      "[('considered', 'like', 'cost'), 'Rloc-']\n",
      "[('like', 'cost', 'and'), 'none']\n",
      "[('cost', 'and', 'efficiency'), 'none']\n",
      "[('and', 'efficiency', 'than'), 'Wci']\n",
      "[('efficiency', 'than', 'the'), 'Wform']\n",
      "[('than', 'the', 'other'), 'none']\n",
      "[('the', 'other', 'five'), 'none']\n",
      "[('other', 'five', 'generation'), 'none']\n",
      "[('five', 'generation', '('), 'none']\n",
      "[('generation', '(', 'iv'), 'none']\n",
      "[('(', 'iv', ')'), 'none']\n",
      "[('iv', ')', 'reactors'), 'none']\n",
      "[('references', 'therefore', ','), 'Wtone']\n",
      "[('therefore', ',', 'this'), 'none']\n",
      "[(',', 'this', 'affects'), 'none']\n",
      "[('this', 'affects', 'the'), 'ArtOrDet']\n",
      "[('affects', 'the', 'automobiles'), 'ArtOrDet']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 'automobiles', 'as'), 'ArtOrDet']\n",
      "[('automobiles', 'as', 'people'), 'none']\n",
      "[('as', 'people', 'purchase'), 'none']\n",
      "[('people', 'purchase', 'more'), 'none']\n",
      "[('purchase', 'more', 'gasoline'), 'none']\n",
      "[('more', 'gasoline', 'powered'), 'none']\n",
      "[('gasoline', 'powered', 'cars'), 'Mec']\n",
      "[('references', 'it', 'gives'), 'Um']\n",
      "[('it', 'gives', 'a'), 'Um']\n",
      "[('gives', 'a', 'well-balance'), 'Um']\n",
      "[('a', 'well-balance', 'medical'), 'Um']\n",
      "[('well-balance', 'medical', 'segment'), 'Um']\n",
      "[('medical', 'segment', ','), 'Um']\n",
      "[('segment', ',', 'an'), 'Um']\n",
      "[(',', 'an', 'advance'), 'none']\n",
      "[('an', 'advance', 'health'), 'none']\n",
      "[('advance', 'health', 'security'), 'none']\n",
      "[('health', 'security', 'cycle'), 'none']\n",
      "[('security', 'cycle', 'as'), 'none']\n",
      "[('cycle', 'as', 'we'), 'none']\n",
      "[('as', 'we', 'reach'), 'none']\n",
      "[('we', 'reach', 'our'), 'none']\n",
      "[('reach', 'our', 'retirement'), 'none']\n",
      "[('our', 'retirement', 'age'), 'none']\n",
      "[('retirement', 'age', 'despite'), 'Um']\n",
      "[('age', 'despite', 'the'), 'Um']\n",
      "[('despite', 'the', 'cost'), 'Um']\n",
      "[('a', 'good', 'government'), 'none']\n",
      "[('good', 'government', 'has'), 'none']\n",
      "[('government', 'has', 'to'), 'none']\n",
      "[('has', 'to', 'come'), 'none']\n",
      "[('to', 'come', 'out'), 'none']\n",
      "[('come', 'out', 'with'), 'none']\n",
      "[('out', 'with', 'a'), 'none']\n",
      "[('with', 'a', 'clear'), 'none']\n",
      "[('a', 'clear', 'policy'), 'none']\n",
      "[('clear', 'policy', 'to'), 'none']\n",
      "[('policy', 'to', 'benefit'), 'none']\n",
      "[('to', 'benefit', 'for'), 'Prep']\n",
      "[('benefit', 'for', 'its'), 'Prep']\n",
      "[('for', 'its', 'people'), 'none']\n",
      "[('its', 'people', 'together'), 'Others']\n",
      "[('people', 'together', 'with'), 'Others']\n",
      "[('together', 'with', 'the'), 'none']\n",
      "[('with', 'the', 'concern'), 'Others']\n",
      "[('the', 'concern', 'towards'), 'Others']\n",
      "[('concern', 'towards', 'the'), 'Others']\n",
      "[('towards', 'the', 'environment'), 'Others']\n",
      "[('the', 'government', 'has'), 'none']\n",
      "[('government', 'has', 'to'), 'none']\n",
      "[('has', 'to', 'ensure'), 'none']\n",
      "[('to', 'ensure', 'that'), 'none']\n",
      "[('ensure', 'that', 'all'), 'none']\n",
      "[('that', 'all', '-'), 'ArtOrDet']\n",
      "[('all', '-', 'elderly'), 'ArtOrDet']\n",
      "[('-', 'elderly', 'has'), 'Wci']\n",
      "[('elderly', 'has', 'a'), 'ArtOrDet']\n",
      "[('has', 'a', 'permanent'), 'SVA']\n",
      "[('a', 'permanent', 'roof'), 'none']\n",
      "[('permanent', 'roof', 'above'), 'none']\n",
      "[('roof', 'above', 'their'), 'none']\n",
      "[('above', 'their', 'head'), 'none']\n",
      "[('their', 'head', 'even'), 'none']\n",
      "[('head', 'even', 'after'), 'none']\n",
      "[('even', 'after', 'retirement'), 'none']\n",
      "[('after', 'retirement', ','), 'none']\n",
      "[('retirement', ',', 'and'), 'Mec']\n",
      "[(',', 'and', 'they'), 'Trans']\n",
      "[('and', 'they', 'could'), 'Vm']\n",
      "[('they', 'could', 'also'), 'Vm']\n",
      "[('could', 'also', 'finance'), 'Vm']\n",
      "[('also', 'finance', 'their'), 'none']\n",
      "[('finance', 'their', 'day-to-day'), 'none']\n",
      "[('their', 'day-to-day', 'living'), 'none']\n",
      "[('day-to-day', 'living', 'expenses'), 'none']\n",
      "[('nowadays', ',', 'people'), 'Um']\n",
      "[(',', 'people', 'are'), 'none']\n",
      "[('people', 'are', 'more'), 'Um']\n",
      "[('are', 'more', 'educated'), 'Um']\n",
      "[('more', 'educated', 'and'), 'none']\n",
      "[('educated', 'and', 'usually'), 'Um']\n",
      "[('and', 'usually', 'having'), 'Um']\n",
      "[('usually', 'having', 'small'), 'Um']\n",
      "[('having', 'small', 'families'), 'Um']\n",
      "[('judging', 'this', 'issue'), 'Rloc-']\n",
      "[('this', 'issue', 'from'), 'Rloc-']\n",
      "[('issue', 'from', 'another'), 'none']\n",
      "[('from', 'another', 'angle'), 'none']\n",
      "[('another', 'angle', ','), 'none']\n",
      "[('angle', ',', 'some'), 'none']\n",
      "[(',', 'some', '-'), 'Mec']\n",
      "[('some', '-', 'argue'), 'Vm']\n",
      "[('-', 'argue', 'that'), 'Vm']\n",
      "[('argue', 'that', 'economic'), 'none']\n",
      "[('that', 'economic', 'factor'), 'none']\n",
      "[('economic', 'factor', 'can'), 'none']\n",
      "[('factor', 'can', 'even'), 'Rloc-']\n",
      "[('can', 'even', 'worsen'), 'Rloc-']\n",
      "[('even', 'worsen', 'the'), 'Rloc-']\n",
      "[('worsen', 'the', 'aging'), 'none']\n",
      "[('the', 'aging', '-'), 'none']\n",
      "[('aging', '-', 'and'), 'Others']\n",
      "[('-', 'and', 'its'), 'Others']\n",
      "[('and', 'its', 'consequences'), 'none']\n",
      "[('arguments', 'presented', 'for'), 'none']\n",
      "[('presented', 'for', 'the'), 'none']\n",
      "[('for', 'the', 'ban'), 'none']\n",
      "[('the', 'ban', 'on'), 'none']\n",
      "[('ban', 'on', 'the'), 'none']\n",
      "[('on', 'the', 'use'), 'WOinc']\n",
      "[('the', 'use', 'of'), 'none']\n",
      "[('use', 'of', 'surveillance'), 'none']\n",
      "[('of', 'surveillance', 'technology'), 'none']\n",
      "[('surveillance', 'technology', 'to'), 'none']\n",
      "[('technology', 'to', 'track'), 'none']\n",
      "[('to', 'track', 'individuals'), 'none']\n",
      "[('track', 'individuals', 'are'), 'none']\n",
      "[('individuals', 'are', 'totally'), 'none']\n",
      "[('are', 'totally', 'flawed'), 'none']\n",
      "[('on', 'the', 'contrary'), 'none']\n",
      "[('the', 'contrary', ','), 'none']\n",
      "[('contrary', ',', 'spending'), 'none']\n",
      "[(',', 'spending', 'in'), 'Wci']\n",
      "[('spending', 'in', 'other'), 'none']\n",
      "[('in', 'other', 'areas'), 'none']\n",
      "[('other', 'areas', 'might'), 'none']\n",
      "[('areas', 'might', 'bring'), 'none']\n",
      "[('might', 'bring', 'benefits'), 'none']\n",
      "[('bring', 'benefits', 'as'), 'none']\n",
      "[('benefits', 'as', 'well'), 'none']\n",
      "[('as', 'well', 'as'), 'none']\n",
      "[('well', 'as', 'solutions'), 'none']\n",
      "[('as', 'solutions', 'for'), 'Prep']\n",
      "[('solutions', 'for', 'the'), 'none']\n",
      "[('for', 'the', 'problem'), 'Prep']\n",
      "[('therefore', ',', 'unlike'), 'none']\n"
     ]
    }
   ],
   "source": [
    "def testandnaivebayes(test_corpus,n,final_dict):\n",
    "    error_classes=final_dict.keys()\n",
    "    sentence_end =\".?!\"\n",
    "    error_list=[]\n",
    "    for i in range(0,len(test_corpus)):\n",
    "        under_observation=[]\n",
    "        flag=0\n",
    "        for j in range(0,n):\n",
    "            if(i+j < len(test_corpus) and test_corpus[i+j] not in sentence_end):\n",
    "                under_observation.append(test_corpus[i+j])\n",
    "            else:\n",
    "                flag=1\n",
    "                break\n",
    "        if flag==0:\n",
    "            oclass=\"none\"\n",
    "            ocount=0\n",
    "            for k in error_classes:\n",
    "                if tuple(under_observation) in final_dict[k].keys() and k!=\"none\":\n",
    "                    x=sum((final_dict[k][tuple(under_observation)].values()))\n",
    "                    if x>ocount:\n",
    "                        ocount = x\n",
    "                        oclass = k\n",
    "                        \n",
    "            if tuple(under_observation) in final_dict['none'].keys():\n",
    "                if final_dict['none'][tuple(under_observation)] > ocount:\n",
    "                    ocount = final_dict['none'][tuple(under_observation)]\n",
    "                    oclass = 'none'\n",
    "            \n",
    "            \n",
    "            error_list.append([tuple(under_observation),oclass])\n",
    "            print ([tuple(under_observation),oclass])\n",
    "    return error_list\n",
    "            \n",
    "\n",
    "\n",
    "test_corpus=readtestcorpus()\n",
    "error_list=testandnaivebayes(test_corpus,3,final_dict)\n",
    "                        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "f3=open(\"test_out.txt\",\"w\")\n",
    "def makeoutput(error_list):\n",
    "    for i in range(0,len(error_list)):\n",
    "        if i>1 and error_list[i][1]==error_list[i-1][1] and error_list[i][1]==error_list[i-2][1]:\n",
    "            if error_list[i][1]== 'none':\n",
    "                f3.write(error_list[i][0][0])\n",
    "            else:\n",
    "                f3.write(error_list[i][0][0]+\"   \"+error_list[i][1])\n",
    "        else:\n",
    "            f3.write(error_list[i][0][0])\n",
    "            \n",
    "makeoutput(error_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
